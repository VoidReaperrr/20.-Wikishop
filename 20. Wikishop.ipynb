{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#1.-Подготовка\" data-toc-modified-id=\"1.-Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>1. Подготовка</a></span></li><li><span><a href=\"#2.-Обучение\" data-toc-modified-id=\"2.-Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>2. Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#Обучим-3-модели\" data-toc-modified-id=\"Обучим-3-модели-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Обучим 3 модели</a></span></li></ul></li><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Вывод</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем библиотеки и познакомимся с данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anon9\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\anon9\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\anon9\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.pipeline import Pipeline\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 159292 entries, 0 to 159450\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/datasets/toxic_comments.csv', index_col=0)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Избавимся от лишнего столбца при выгрузке данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "првоерим дубликаты, пропусоков нет, это виднго из `info`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем функцию лемматизации и подчищаем тескт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def lemmatize_df(text):\n",
    "    text = text.lower()\n",
    "    clear_text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    return \" \".join(clear_text.split())\n",
    "\n",
    "df['text'] = df['text'].apply(lemmatize_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d aww he matches this background colour i m se...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man i m really not trying to edit war it s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>more i can t make any real suggestions on impr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  explanation why the edits made under my userna...      0\n",
       "1  d aww he matches this background colour i m se...      0\n",
       "2  hey man i m really not trying to edit war it s...      0\n",
       "3  more i can t make any real suggestions on impr...      0\n",
       "4  you sir are my hero any chance you remember wh...      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,               \n",
    "                \"N\": wordnet.NOUN,              \n",
    "                \"V\": wordnet.VERB,              \n",
    "                \"R\": wordnet.ADV                \n",
    "               }  \n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemm_text(text):\n",
    "    text = [lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(text)]\n",
    "    return ' '.join(text)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "001a89f6d7924e0abd1a6f9da6540679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159292 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 42min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df['text'] = df['text'].progress_apply(lemm_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation why the edits make under my userna...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d aww he match this background colour i m seem...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man i m really not try to edit war it s ju...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>more i can t make any real suggestion on impro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you sir be my hero any chance you remember wha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>congratulation from me a well use the tool wel...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cocksucker before you piss around on my work</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>your vandalism to the matt shirvington article...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sorry if the word nonsense be offensive to you...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>alignment on this subject and which be contrar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  explanation why the edits make under my userna...      0\n",
       "1  d aww he match this background colour i m seem...      0\n",
       "2  hey man i m really not try to edit war it s ju...      0\n",
       "3  more i can t make any real suggestion on impro...      0\n",
       "4  you sir be my hero any chance you remember wha...      0\n",
       "5  congratulation from me a well use the tool wel...      0\n",
       "6       cocksucker before you piss around on my work      1\n",
       "7  your vandalism to the matt shirvington article...      0\n",
       "8  sorry if the word nonsense be offensive to you...      0\n",
       "9  alignment on this subject and which be contrar...      0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Супер, все почистилось, далее удалим столбец с неподчищенным текстом "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 159292 entries, 0 to 159450\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим данные на дисбпланс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    143106\n",
      "1     16186\n",
      "Name: toxic, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "toxic_counts = (df['toxic'].value_counts())\n",
    "plt.pie(toxic_counts, labels=toxic_counts.index, autopct='%1.1f%%', startangle=140)\n",
    "plt.title('Распределение \"toxic\" в датасете');\n",
    "print(df['toxic'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем в модели использовать баланс, указывать параметр"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделим фичи и целевой признак  \n",
    "Так же разделим данные на выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df['toxic']\n",
    "features = df.drop(['toxic'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер тренировочной выборки: (143362, 1)\n",
      "Размер тестовой выборки: (15930, 1)\n",
      "Wall time: 253 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\anon9\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target,\n",
    "                                                                            test_size=0.1,\n",
    "                                                                            random_state=12345)\n",
    "\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stopwords_list = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "print(\"Размер тренировочной выборки:\", features_train.shape)\n",
    "print(\"Размер тестовой выборки:\", features_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучим 3 модели "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anon9\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\anon9\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\anon9\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\anon9\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\anon9\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\anon9\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\anon9\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\anon9\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\anon9\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры: {'classifier__C': 10, 'tfidf__ngram_range': (1, 2)}\n",
      "F1-метрика на тренировочных  данных: 0.7790387356455555\n",
      "Wall time: 7min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words=stopwords_list)),\n",
    "    ('classifier', LogisticRegression(class_weight='balanced'))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2)], \n",
    "    'classifier__C': [0.1, 1, 10], \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring='f1')\n",
    "\n",
    "grid_search.fit(features_train['text'], target_train)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "best_lr_f1_train = grid_search.best_score_\n",
    "\n",
    "print(\"Лучшие параметры:\", best_params)\n",
    "print(\"F1-метрика на тренировочных  данных:\", best_lr_f1_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "0:\tlearn: 0.6827330\ttotal: 747ms\tremaining: 36.6s\n",
      "1:\tlearn: 0.6723454\ttotal: 1.31s\tremaining: 31.5s\n",
      "2:\tlearn: 0.6618170\ttotal: 1.89s\tremaining: 29.5s\n",
      "3:\tlearn: 0.6514694\ttotal: 2.46s\tremaining: 28.3s\n",
      "4:\tlearn: 0.6416251\ttotal: 3.04s\tremaining: 27.4s\n",
      "5:\tlearn: 0.6319695\ttotal: 3.6s\tremaining: 26.4s\n",
      "6:\tlearn: 0.6228031\ttotal: 4.17s\tremaining: 25.6s\n",
      "7:\tlearn: 0.6137664\ttotal: 4.73s\tremaining: 24.8s\n",
      "8:\tlearn: 0.6051267\ttotal: 5.3s\tremaining: 24.2s\n",
      "9:\tlearn: 0.5967318\ttotal: 5.87s\tremaining: 23.5s\n",
      "10:\tlearn: 0.5881397\ttotal: 6.44s\tremaining: 22.8s\n",
      "11:\tlearn: 0.5793694\ttotal: 7.03s\tremaining: 22.3s\n",
      "12:\tlearn: 0.5710639\ttotal: 7.62s\tremaining: 21.7s\n",
      "13:\tlearn: 0.5634120\ttotal: 8.22s\tremaining: 21.1s\n",
      "14:\tlearn: 0.5557311\ttotal: 8.83s\tremaining: 20.6s\n",
      "15:\tlearn: 0.5480815\ttotal: 9.48s\tremaining: 20.2s\n",
      "16:\tlearn: 0.5406133\ttotal: 10.2s\tremaining: 19.8s\n",
      "17:\tlearn: 0.5334438\ttotal: 10.9s\tremaining: 19.3s\n",
      "18:\tlearn: 0.5266132\ttotal: 11.5s\tremaining: 18.7s\n",
      "19:\tlearn: 0.5197401\ttotal: 12.1s\tremaining: 18.1s\n",
      "20:\tlearn: 0.5130819\ttotal: 12.6s\tremaining: 17.4s\n",
      "21:\tlearn: 0.5063682\ttotal: 13.2s\tremaining: 16.8s\n",
      "22:\tlearn: 0.5000642\ttotal: 13.7s\tremaining: 16.1s\n",
      "23:\tlearn: 0.4937980\ttotal: 14.3s\tremaining: 15.5s\n",
      "24:\tlearn: 0.4874269\ttotal: 14.9s\tremaining: 14.9s\n",
      "25:\tlearn: 0.4813631\ttotal: 15.4s\tremaining: 14.2s\n",
      "26:\tlearn: 0.4753970\ttotal: 16s\tremaining: 13.6s\n",
      "27:\tlearn: 0.4699026\ttotal: 16.5s\tremaining: 13s\n",
      "28:\tlearn: 0.4641256\ttotal: 17.1s\tremaining: 12.4s\n",
      "29:\tlearn: 0.4587792\ttotal: 17.7s\tremaining: 11.8s\n",
      "30:\tlearn: 0.4533486\ttotal: 18.2s\tremaining: 11.2s\n",
      "31:\tlearn: 0.4481931\ttotal: 18.8s\tremaining: 10.6s\n",
      "32:\tlearn: 0.4430599\ttotal: 19.3s\tremaining: 9.96s\n",
      "33:\tlearn: 0.4382700\ttotal: 19.9s\tremaining: 9.35s\n",
      "34:\tlearn: 0.4332431\ttotal: 20.4s\tremaining: 8.75s\n",
      "35:\tlearn: 0.4284894\ttotal: 21s\tremaining: 8.15s\n",
      "36:\tlearn: 0.4239083\ttotal: 21.5s\tremaining: 7.56s\n",
      "37:\tlearn: 0.4193562\ttotal: 22.1s\tremaining: 6.97s\n",
      "38:\tlearn: 0.4149792\ttotal: 22.6s\tremaining: 6.38s\n",
      "39:\tlearn: 0.4106231\ttotal: 23.2s\tremaining: 5.8s\n",
      "40:\tlearn: 0.4063783\ttotal: 23.8s\tremaining: 5.23s\n",
      "41:\tlearn: 0.4022496\ttotal: 24.4s\tremaining: 4.66s\n",
      "42:\tlearn: 0.3982564\ttotal: 25.1s\tremaining: 4.08s\n",
      "43:\tlearn: 0.3943698\ttotal: 25.6s\tremaining: 3.5s\n",
      "44:\tlearn: 0.3903949\ttotal: 26.3s\tremaining: 2.92s\n",
      "45:\tlearn: 0.3866129\ttotal: 26.9s\tremaining: 2.34s\n",
      "46:\tlearn: 0.3828777\ttotal: 27.5s\tremaining: 1.75s\n",
      "47:\tlearn: 0.3793435\ttotal: 28.1s\tremaining: 1.17s\n",
      "48:\tlearn: 0.3759500\ttotal: 28.8s\tremaining: 587ms\n",
      "49:\tlearn: 0.3724679\ttotal: 29.4s\tremaining: 0us\n",
      "[CV] END .................................learning_rate=0.01; total time=  36.3s\n",
      "0:\tlearn: 0.6822689\ttotal: 591ms\tremaining: 28.9s\n",
      "1:\tlearn: 0.6718020\ttotal: 1.2s\tremaining: 28.9s\n",
      "2:\tlearn: 0.6617033\ttotal: 1.84s\tremaining: 28.9s\n",
      "3:\tlearn: 0.6520105\ttotal: 2.44s\tremaining: 28s\n",
      "4:\tlearn: 0.6420916\ttotal: 3.04s\tremaining: 27.3s\n",
      "5:\tlearn: 0.6323184\ttotal: 3.6s\tremaining: 26.4s\n",
      "6:\tlearn: 0.6232453\ttotal: 4.18s\tremaining: 25.7s\n",
      "7:\tlearn: 0.6138777\ttotal: 4.77s\tremaining: 25s\n",
      "8:\tlearn: 0.6051947\ttotal: 5.38s\tremaining: 24.5s\n",
      "9:\tlearn: 0.5965738\ttotal: 6s\tremaining: 24s\n",
      "10:\tlearn: 0.5881828\ttotal: 6.6s\tremaining: 23.4s\n",
      "11:\tlearn: 0.5796921\ttotal: 7.17s\tremaining: 22.7s\n",
      "12:\tlearn: 0.5715181\ttotal: 7.74s\tremaining: 22s\n",
      "13:\tlearn: 0.5636238\ttotal: 8.33s\tremaining: 21.4s\n",
      "14:\tlearn: 0.5561013\ttotal: 8.92s\tremaining: 20.8s\n",
      "15:\tlearn: 0.5483637\ttotal: 9.49s\tremaining: 20.2s\n",
      "16:\tlearn: 0.5408851\ttotal: 10.1s\tremaining: 19.7s\n",
      "17:\tlearn: 0.5337637\ttotal: 10.7s\tremaining: 19s\n",
      "18:\tlearn: 0.5266211\ttotal: 11.3s\tremaining: 18.4s\n",
      "19:\tlearn: 0.5196523\ttotal: 11.8s\tremaining: 17.7s\n",
      "20:\tlearn: 0.5129481\ttotal: 12.3s\tremaining: 17.1s\n",
      "21:\tlearn: 0.5063998\ttotal: 12.9s\tremaining: 16.5s\n",
      "22:\tlearn: 0.4999207\ttotal: 13.6s\tremaining: 15.9s\n",
      "23:\tlearn: 0.4936745\ttotal: 14.1s\tremaining: 15.3s\n",
      "24:\tlearn: 0.4876314\ttotal: 14.7s\tremaining: 14.7s\n",
      "25:\tlearn: 0.4819001\ttotal: 15.3s\tremaining: 14.1s\n",
      "26:\tlearn: 0.4759196\ttotal: 15.9s\tremaining: 13.5s\n",
      "27:\tlearn: 0.4703072\ttotal: 16.5s\tremaining: 12.9s\n",
      "28:\tlearn: 0.4646890\ttotal: 17.1s\tremaining: 12.4s\n",
      "29:\tlearn: 0.4593695\ttotal: 17.7s\tremaining: 11.8s\n",
      "30:\tlearn: 0.4541061\ttotal: 18.3s\tremaining: 11.2s\n",
      "31:\tlearn: 0.4489528\ttotal: 18.8s\tremaining: 10.6s\n",
      "32:\tlearn: 0.4439270\ttotal: 19.4s\tremaining: 9.97s\n",
      "33:\tlearn: 0.4390659\ttotal: 19.9s\tremaining: 9.37s\n",
      "34:\tlearn: 0.4343043\ttotal: 20.5s\tremaining: 8.77s\n",
      "35:\tlearn: 0.4296413\ttotal: 21s\tremaining: 8.16s\n",
      "36:\tlearn: 0.4248809\ttotal: 21.6s\tremaining: 7.59s\n",
      "37:\tlearn: 0.4204137\ttotal: 22.2s\tremaining: 7s\n",
      "38:\tlearn: 0.4161996\ttotal: 22.7s\tremaining: 6.4s\n",
      "39:\tlearn: 0.4118836\ttotal: 23.2s\tremaining: 5.8s\n",
      "40:\tlearn: 0.4077964\ttotal: 23.7s\tremaining: 5.2s\n",
      "41:\tlearn: 0.4038021\ttotal: 24.2s\tremaining: 4.61s\n",
      "42:\tlearn: 0.3998590\ttotal: 24.7s\tremaining: 4.02s\n",
      "43:\tlearn: 0.3958616\ttotal: 25.2s\tremaining: 3.44s\n",
      "44:\tlearn: 0.3922021\ttotal: 25.7s\tremaining: 2.86s\n",
      "45:\tlearn: 0.3886038\ttotal: 26.2s\tremaining: 2.28s\n",
      "46:\tlearn: 0.3850572\ttotal: 26.7s\tremaining: 1.71s\n",
      "47:\tlearn: 0.3814767\ttotal: 27.3s\tremaining: 1.14s\n",
      "48:\tlearn: 0.3781317\ttotal: 27.8s\tremaining: 567ms\n",
      "49:\tlearn: 0.3746708\ttotal: 28.3s\tremaining: 0us\n",
      "[CV] END .................................learning_rate=0.01; total time=  35.2s\n",
      "0:\tlearn: 0.6825038\ttotal: 526ms\tremaining: 25.8s\n",
      "1:\tlearn: 0.6719341\ttotal: 1.04s\tremaining: 24.9s\n",
      "2:\tlearn: 0.6613231\ttotal: 1.55s\tremaining: 24.3s\n",
      "3:\tlearn: 0.6511240\ttotal: 2.06s\tremaining: 23.7s\n",
      "4:\tlearn: 0.6410354\ttotal: 2.56s\tremaining: 23.1s\n",
      "5:\tlearn: 0.6312303\ttotal: 3.07s\tremaining: 22.5s\n",
      "6:\tlearn: 0.6215995\ttotal: 3.58s\tremaining: 22s\n",
      "7:\tlearn: 0.6126794\ttotal: 4.1s\tremaining: 21.5s\n",
      "8:\tlearn: 0.6038136\ttotal: 4.61s\tremaining: 21s\n",
      "9:\tlearn: 0.5949583\ttotal: 5.13s\tremaining: 20.5s\n",
      "10:\tlearn: 0.5863616\ttotal: 5.73s\tremaining: 20.3s\n",
      "11:\tlearn: 0.5781315\ttotal: 6.29s\tremaining: 19.9s\n",
      "12:\tlearn: 0.5698057\ttotal: 6.84s\tremaining: 19.5s\n",
      "13:\tlearn: 0.5620224\ttotal: 7.36s\tremaining: 18.9s\n",
      "14:\tlearn: 0.5541150\ttotal: 7.86s\tremaining: 18.4s\n",
      "15:\tlearn: 0.5466207\ttotal: 8.36s\tremaining: 17.8s\n",
      "16:\tlearn: 0.5395946\ttotal: 8.87s\tremaining: 17.2s\n",
      "17:\tlearn: 0.5323248\ttotal: 9.38s\tremaining: 16.7s\n",
      "18:\tlearn: 0.5252726\ttotal: 9.89s\tremaining: 16.1s\n",
      "19:\tlearn: 0.5184902\ttotal: 10.4s\tremaining: 15.6s\n",
      "20:\tlearn: 0.5114983\ttotal: 10.9s\tremaining: 15.1s\n",
      "21:\tlearn: 0.5050273\ttotal: 11.5s\tremaining: 14.6s\n",
      "22:\tlearn: 0.4985544\ttotal: 12s\tremaining: 14.1s\n",
      "23:\tlearn: 0.4921774\ttotal: 12.5s\tremaining: 13.6s\n",
      "24:\tlearn: 0.4862290\ttotal: 13s\tremaining: 13s\n",
      "25:\tlearn: 0.4803664\ttotal: 13.6s\tremaining: 12.5s\n",
      "26:\tlearn: 0.4745569\ttotal: 14.1s\tremaining: 12s\n",
      "27:\tlearn: 0.4685835\ttotal: 14.6s\tremaining: 11.5s\n",
      "28:\tlearn: 0.4630460\ttotal: 15.2s\tremaining: 11s\n",
      "29:\tlearn: 0.4576815\ttotal: 15.7s\tremaining: 10.5s\n",
      "30:\tlearn: 0.4524695\ttotal: 16.2s\tremaining: 9.95s\n",
      "31:\tlearn: 0.4471672\ttotal: 16.8s\tremaining: 9.46s\n",
      "32:\tlearn: 0.4421125\ttotal: 17.4s\tremaining: 8.94s\n",
      "33:\tlearn: 0.4370962\ttotal: 17.9s\tremaining: 8.44s\n",
      "34:\tlearn: 0.4326055\ttotal: 18.5s\tremaining: 7.92s\n",
      "35:\tlearn: 0.4278753\ttotal: 19s\tremaining: 7.4s\n",
      "36:\tlearn: 0.4231667\ttotal: 19.6s\tremaining: 6.87s\n",
      "37:\tlearn: 0.4186282\ttotal: 20.2s\tremaining: 6.37s\n",
      "38:\tlearn: 0.4142484\ttotal: 20.7s\tremaining: 5.85s\n",
      "39:\tlearn: 0.4100744\ttotal: 21.3s\tremaining: 5.33s\n",
      "40:\tlearn: 0.4059803\ttotal: 21.9s\tremaining: 4.8s\n",
      "41:\tlearn: 0.4017434\ttotal: 22.5s\tremaining: 4.28s\n",
      "42:\tlearn: 0.3977530\ttotal: 23s\tremaining: 3.75s\n",
      "43:\tlearn: 0.3939061\ttotal: 23.6s\tremaining: 3.21s\n",
      "44:\tlearn: 0.3900657\ttotal: 24.1s\tremaining: 2.68s\n",
      "45:\tlearn: 0.3863522\ttotal: 24.6s\tremaining: 2.14s\n",
      "46:\tlearn: 0.3827526\ttotal: 25.2s\tremaining: 1.6s\n",
      "47:\tlearn: 0.3791714\ttotal: 25.7s\tremaining: 1.07s\n",
      "48:\tlearn: 0.3757629\ttotal: 26.2s\tremaining: 535ms\n",
      "49:\tlearn: 0.3725227\ttotal: 26.7s\tremaining: 0us\n",
      "[CV] END .................................learning_rate=0.01; total time=  33.2s\n",
      "0:\tlearn: 0.5960016\ttotal: 547ms\tremaining: 26.8s\n",
      "1:\tlearn: 0.5173415\ttotal: 1.06s\tremaining: 25.5s\n",
      "2:\tlearn: 0.4543266\ttotal: 1.59s\tremaining: 24.9s\n",
      "3:\tlearn: 0.4039670\ttotal: 2.1s\tremaining: 24.2s\n",
      "4:\tlearn: 0.3655582\ttotal: 2.62s\tremaining: 23.6s\n",
      "5:\tlearn: 0.3377966\ttotal: 3.14s\tremaining: 23s\n",
      "6:\tlearn: 0.3148497\ttotal: 3.66s\tremaining: 22.5s\n",
      "7:\tlearn: 0.2962961\ttotal: 4.19s\tremaining: 22s\n",
      "8:\tlearn: 0.2823892\ttotal: 4.72s\tremaining: 21.5s\n",
      "9:\tlearn: 0.2706793\ttotal: 5.24s\tremaining: 21s\n",
      "10:\tlearn: 0.2602875\ttotal: 5.76s\tremaining: 20.4s\n",
      "11:\tlearn: 0.2527711\ttotal: 6.29s\tremaining: 19.9s\n",
      "12:\tlearn: 0.2466935\ttotal: 6.8s\tremaining: 19.3s\n",
      "13:\tlearn: 0.2411750\ttotal: 7.31s\tremaining: 18.8s\n",
      "14:\tlearn: 0.2366356\ttotal: 7.82s\tremaining: 18.3s\n",
      "15:\tlearn: 0.2330623\ttotal: 8.35s\tremaining: 17.7s\n",
      "16:\tlearn: 0.2297714\ttotal: 8.86s\tremaining: 17.2s\n",
      "17:\tlearn: 0.2269257\ttotal: 9.37s\tremaining: 16.7s\n",
      "18:\tlearn: 0.2235473\ttotal: 9.89s\tremaining: 16.1s\n",
      "19:\tlearn: 0.2213667\ttotal: 10.4s\tremaining: 15.6s\n",
      "20:\tlearn: 0.2191138\ttotal: 10.9s\tremaining: 15.1s\n",
      "21:\tlearn: 0.2173583\ttotal: 11.4s\tremaining: 14.6s\n",
      "22:\tlearn: 0.2156672\ttotal: 12s\tremaining: 14s\n",
      "23:\tlearn: 0.2141026\ttotal: 12.5s\tremaining: 13.5s\n",
      "24:\tlearn: 0.2122471\ttotal: 13.1s\tremaining: 13.1s\n",
      "25:\tlearn: 0.2109422\ttotal: 13.6s\tremaining: 12.5s\n",
      "26:\tlearn: 0.2096701\ttotal: 14.2s\tremaining: 12.1s\n",
      "27:\tlearn: 0.2085007\ttotal: 14.7s\tremaining: 11.5s\n",
      "28:\tlearn: 0.2074767\ttotal: 15.2s\tremaining: 11s\n",
      "29:\tlearn: 0.2064681\ttotal: 15.7s\tremaining: 10.5s\n",
      "30:\tlearn: 0.2051993\ttotal: 16.2s\tremaining: 9.95s\n",
      "31:\tlearn: 0.2039688\ttotal: 16.8s\tremaining: 9.46s\n",
      "32:\tlearn: 0.2029402\ttotal: 17.4s\tremaining: 8.94s\n",
      "33:\tlearn: 0.2020491\ttotal: 17.9s\tremaining: 8.42s\n",
      "34:\tlearn: 0.2010999\ttotal: 18.4s\tremaining: 7.89s\n",
      "35:\tlearn: 0.2002269\ttotal: 19s\tremaining: 7.37s\n",
      "36:\tlearn: 0.1994176\ttotal: 19.5s\tremaining: 6.86s\n",
      "37:\tlearn: 0.1980716\ttotal: 20.1s\tremaining: 6.36s\n",
      "38:\tlearn: 0.1973899\ttotal: 20.7s\tremaining: 5.84s\n",
      "39:\tlearn: 0.1965128\ttotal: 21.2s\tremaining: 5.31s\n",
      "40:\tlearn: 0.1957632\ttotal: 21.8s\tremaining: 4.78s\n",
      "41:\tlearn: 0.1950257\ttotal: 22.3s\tremaining: 4.24s\n",
      "42:\tlearn: 0.1943428\ttotal: 22.8s\tremaining: 3.71s\n",
      "43:\tlearn: 0.1935156\ttotal: 23.4s\tremaining: 3.19s\n",
      "44:\tlearn: 0.1921766\ttotal: 23.9s\tremaining: 2.66s\n",
      "45:\tlearn: 0.1915711\ttotal: 24.6s\tremaining: 2.13s\n",
      "46:\tlearn: 0.1907712\ttotal: 25.1s\tremaining: 1.6s\n",
      "47:\tlearn: 0.1901866\ttotal: 25.7s\tremaining: 1.07s\n",
      "48:\tlearn: 0.1891881\ttotal: 26.3s\tremaining: 536ms\n",
      "49:\tlearn: 0.1885053\ttotal: 26.8s\tremaining: 0us\n",
      "[CV] END ..................................learning_rate=0.1; total time=  33.3s\n",
      "0:\tlearn: 0.5918381\ttotal: 569ms\tremaining: 27.9s\n",
      "1:\tlearn: 0.5154015\ttotal: 1.12s\tremaining: 26.8s\n",
      "2:\tlearn: 0.4530172\ttotal: 1.66s\tremaining: 25.9s\n",
      "3:\tlearn: 0.4069908\ttotal: 2.21s\tremaining: 25.4s\n",
      "4:\tlearn: 0.3697497\ttotal: 2.75s\tremaining: 24.8s\n",
      "5:\tlearn: 0.3406169\ttotal: 3.3s\tremaining: 24.2s\n",
      "6:\tlearn: 0.3176220\ttotal: 3.85s\tremaining: 23.7s\n",
      "7:\tlearn: 0.2991326\ttotal: 4.41s\tremaining: 23.2s\n",
      "8:\tlearn: 0.2850091\ttotal: 4.96s\tremaining: 22.6s\n",
      "9:\tlearn: 0.2721344\ttotal: 5.51s\tremaining: 22.1s\n",
      "10:\tlearn: 0.2629094\ttotal: 6.06s\tremaining: 21.5s\n",
      "11:\tlearn: 0.2551413\ttotal: 6.64s\tremaining: 21s\n",
      "12:\tlearn: 0.2490263\ttotal: 7.24s\tremaining: 20.6s\n",
      "13:\tlearn: 0.2438192\ttotal: 7.84s\tremaining: 20.2s\n",
      "14:\tlearn: 0.2393065\ttotal: 8.46s\tremaining: 19.7s\n",
      "15:\tlearn: 0.2354795\ttotal: 9.03s\tremaining: 19.2s\n",
      "16:\tlearn: 0.2322370\ttotal: 9.64s\tremaining: 18.7s\n",
      "17:\tlearn: 0.2286596\ttotal: 10.3s\tremaining: 18.3s\n",
      "18:\tlearn: 0.2259921\ttotal: 10.9s\tremaining: 17.8s\n",
      "19:\tlearn: 0.2237127\ttotal: 11.4s\tremaining: 17.1s\n",
      "20:\tlearn: 0.2215917\ttotal: 12s\tremaining: 16.6s\n",
      "21:\tlearn: 0.2194183\ttotal: 12.6s\tremaining: 16s\n",
      "22:\tlearn: 0.2173173\ttotal: 13.2s\tremaining: 15.5s\n",
      "23:\tlearn: 0.2157807\ttotal: 13.9s\tremaining: 15s\n",
      "24:\tlearn: 0.2142714\ttotal: 14.5s\tremaining: 14.5s\n",
      "25:\tlearn: 0.2123878\ttotal: 15.1s\tremaining: 13.9s\n",
      "26:\tlearn: 0.2112347\ttotal: 15.7s\tremaining: 13.4s\n",
      "27:\tlearn: 0.2101893\ttotal: 16.3s\tremaining: 12.8s\n",
      "28:\tlearn: 0.2091786\ttotal: 16.9s\tremaining: 12.2s\n",
      "29:\tlearn: 0.2080339\ttotal: 17.5s\tremaining: 11.6s\n",
      "30:\tlearn: 0.2066010\ttotal: 18s\tremaining: 11.1s\n",
      "31:\tlearn: 0.2056157\ttotal: 18.7s\tremaining: 10.5s\n",
      "32:\tlearn: 0.2046478\ttotal: 19.3s\tremaining: 9.92s\n",
      "33:\tlearn: 0.2037571\ttotal: 19.9s\tremaining: 9.35s\n",
      "34:\tlearn: 0.2028478\ttotal: 20.4s\tremaining: 8.75s\n",
      "35:\tlearn: 0.2018920\ttotal: 21s\tremaining: 8.17s\n",
      "36:\tlearn: 0.2007384\ttotal: 21.6s\tremaining: 7.59s\n",
      "37:\tlearn: 0.1996918\ttotal: 22.2s\tremaining: 7s\n",
      "38:\tlearn: 0.1989969\ttotal: 22.7s\tremaining: 6.4s\n",
      "39:\tlearn: 0.1980955\ttotal: 23.3s\tremaining: 5.83s\n",
      "40:\tlearn: 0.1973726\ttotal: 23.9s\tremaining: 5.24s\n",
      "41:\tlearn: 0.1965003\ttotal: 24.5s\tremaining: 4.67s\n",
      "42:\tlearn: 0.1956315\ttotal: 25.1s\tremaining: 4.09s\n",
      "43:\tlearn: 0.1947546\ttotal: 25.7s\tremaining: 3.51s\n",
      "44:\tlearn: 0.1941911\ttotal: 26.4s\tremaining: 2.93s\n",
      "45:\tlearn: 0.1932700\ttotal: 27s\tremaining: 2.34s\n",
      "46:\tlearn: 0.1926910\ttotal: 27.5s\tremaining: 1.76s\n",
      "47:\tlearn: 0.1920663\ttotal: 28.1s\tremaining: 1.17s\n",
      "48:\tlearn: 0.1912608\ttotal: 28.6s\tremaining: 584ms\n",
      "49:\tlearn: 0.1906846\ttotal: 29.1s\tremaining: 0us\n",
      "[CV] END ..................................learning_rate=0.1; total time=  35.7s\n",
      "0:\tlearn: 0.5939380\ttotal: 546ms\tremaining: 26.8s\n",
      "1:\tlearn: 0.5135203\ttotal: 1.09s\tremaining: 26.3s\n",
      "2:\tlearn: 0.4476422\ttotal: 1.63s\tremaining: 25.6s\n",
      "3:\tlearn: 0.4018300\ttotal: 2.21s\tremaining: 25.4s\n",
      "4:\tlearn: 0.3645509\ttotal: 2.79s\tremaining: 25.1s\n",
      "5:\tlearn: 0.3347889\ttotal: 3.37s\tremaining: 24.7s\n",
      "6:\tlearn: 0.3120835\ttotal: 3.95s\tremaining: 24.2s\n",
      "7:\tlearn: 0.2949414\ttotal: 4.51s\tremaining: 23.7s\n",
      "8:\tlearn: 0.2809370\ttotal: 5.08s\tremaining: 23.2s\n",
      "9:\tlearn: 0.2695859\ttotal: 5.71s\tremaining: 22.9s\n",
      "10:\tlearn: 0.2607964\ttotal: 6.32s\tremaining: 22.4s\n",
      "11:\tlearn: 0.2531257\ttotal: 6.94s\tremaining: 22s\n",
      "12:\tlearn: 0.2458971\ttotal: 7.55s\tremaining: 21.5s\n",
      "13:\tlearn: 0.2405780\ttotal: 8.11s\tremaining: 20.9s\n",
      "14:\tlearn: 0.2362219\ttotal: 8.65s\tremaining: 20.2s\n",
      "15:\tlearn: 0.2324309\ttotal: 9.22s\tremaining: 19.6s\n",
      "16:\tlearn: 0.2288014\ttotal: 9.79s\tremaining: 19s\n",
      "17:\tlearn: 0.2257835\ttotal: 10.4s\tremaining: 18.5s\n",
      "18:\tlearn: 0.2231380\ttotal: 11s\tremaining: 17.9s\n",
      "19:\tlearn: 0.2210883\ttotal: 11.6s\tremaining: 17.4s\n",
      "20:\tlearn: 0.2189302\ttotal: 12.1s\tremaining: 16.8s\n",
      "21:\tlearn: 0.2172841\ttotal: 12.7s\tremaining: 16.2s\n",
      "22:\tlearn: 0.2150138\ttotal: 13.3s\tremaining: 15.6s\n",
      "23:\tlearn: 0.2130205\ttotal: 13.9s\tremaining: 15s\n",
      "24:\tlearn: 0.2114147\ttotal: 14.4s\tremaining: 14.4s\n",
      "25:\tlearn: 0.2102933\ttotal: 15s\tremaining: 13.8s\n",
      "26:\tlearn: 0.2091234\ttotal: 15.5s\tremaining: 13.2s\n",
      "27:\tlearn: 0.2077628\ttotal: 16.1s\tremaining: 12.6s\n",
      "28:\tlearn: 0.2064915\ttotal: 16.6s\tremaining: 12s\n",
      "29:\tlearn: 0.2053938\ttotal: 17.2s\tremaining: 11.4s\n",
      "30:\tlearn: 0.2043268\ttotal: 17.7s\tremaining: 10.8s\n",
      "31:\tlearn: 0.2030600\ttotal: 18.2s\tremaining: 10.3s\n",
      "32:\tlearn: 0.2017336\ttotal: 18.8s\tremaining: 9.67s\n",
      "33:\tlearn: 0.2008212\ttotal: 19.3s\tremaining: 9.1s\n",
      "34:\tlearn: 0.1998652\ttotal: 19.9s\tremaining: 8.52s\n",
      "35:\tlearn: 0.1990813\ttotal: 20.4s\tremaining: 7.95s\n",
      "36:\tlearn: 0.1977683\ttotal: 21s\tremaining: 7.38s\n",
      "37:\tlearn: 0.1965287\ttotal: 21.5s\tremaining: 6.8s\n",
      "38:\tlearn: 0.1957143\ttotal: 22.1s\tremaining: 6.23s\n",
      "39:\tlearn: 0.1949988\ttotal: 22.6s\tremaining: 5.66s\n",
      "40:\tlearn: 0.1942967\ttotal: 23.2s\tremaining: 5.09s\n",
      "41:\tlearn: 0.1937093\ttotal: 23.7s\tremaining: 4.52s\n",
      "42:\tlearn: 0.1931011\ttotal: 24.3s\tremaining: 3.96s\n",
      "43:\tlearn: 0.1924780\ttotal: 24.9s\tremaining: 3.39s\n",
      "44:\tlearn: 0.1916079\ttotal: 25.4s\tremaining: 2.83s\n",
      "45:\tlearn: 0.1908568\ttotal: 26s\tremaining: 2.26s\n",
      "46:\tlearn: 0.1901562\ttotal: 26.5s\tremaining: 1.69s\n",
      "47:\tlearn: 0.1895909\ttotal: 27s\tremaining: 1.13s\n",
      "48:\tlearn: 0.1888412\ttotal: 27.6s\tremaining: 564ms\n",
      "49:\tlearn: 0.1880141\ttotal: 28.2s\tremaining: 0us\n",
      "[CV] END ..................................learning_rate=0.1; total time=  34.6s\n",
      "0:\tlearn: 0.5141984\ttotal: 584ms\tremaining: 28.6s\n",
      "1:\tlearn: 0.4021752\ttotal: 1.16s\tremaining: 27.8s\n",
      "2:\tlearn: 0.3357693\ttotal: 1.71s\tremaining: 26.9s\n",
      "3:\tlearn: 0.2944672\ttotal: 2.29s\tremaining: 26.4s\n",
      "4:\tlearn: 0.2696507\ttotal: 2.86s\tremaining: 25.7s\n",
      "5:\tlearn: 0.2533507\ttotal: 3.4s\tremaining: 25s\n",
      "6:\tlearn: 0.2419362\ttotal: 3.93s\tremaining: 24.2s\n",
      "7:\tlearn: 0.2318598\ttotal: 4.47s\tremaining: 23.5s\n",
      "8:\tlearn: 0.2257659\ttotal: 5.01s\tremaining: 22.8s\n",
      "9:\tlearn: 0.2207528\ttotal: 5.55s\tremaining: 22.2s\n",
      "10:\tlearn: 0.2172820\ttotal: 6.08s\tremaining: 21.5s\n",
      "11:\tlearn: 0.2133142\ttotal: 6.61s\tremaining: 20.9s\n",
      "12:\tlearn: 0.2109791\ttotal: 7.14s\tremaining: 20.3s\n",
      "13:\tlearn: 0.2078753\ttotal: 7.71s\tremaining: 19.8s\n",
      "14:\tlearn: 0.2055446\ttotal: 8.25s\tremaining: 19.3s\n",
      "15:\tlearn: 0.2033588\ttotal: 8.78s\tremaining: 18.7s\n",
      "16:\tlearn: 0.2013482\ttotal: 9.31s\tremaining: 18.1s\n",
      "17:\tlearn: 0.1995150\ttotal: 9.85s\tremaining: 17.5s\n",
      "18:\tlearn: 0.1977268\ttotal: 10.4s\tremaining: 16.9s\n",
      "19:\tlearn: 0.1962893\ttotal: 10.9s\tremaining: 16.4s\n",
      "20:\tlearn: 0.1938694\ttotal: 11.5s\tremaining: 15.8s\n",
      "21:\tlearn: 0.1925331\ttotal: 12s\tremaining: 15.3s\n",
      "22:\tlearn: 0.1909224\ttotal: 12.5s\tremaining: 14.7s\n",
      "23:\tlearn: 0.1894633\ttotal: 13.1s\tremaining: 14.2s\n",
      "24:\tlearn: 0.1883155\ttotal: 13.6s\tremaining: 13.6s\n",
      "25:\tlearn: 0.1869091\ttotal: 14.1s\tremaining: 13s\n",
      "26:\tlearn: 0.1859431\ttotal: 14.7s\tremaining: 12.5s\n",
      "27:\tlearn: 0.1848830\ttotal: 15.2s\tremaining: 11.9s\n",
      "28:\tlearn: 0.1839128\ttotal: 15.7s\tremaining: 11.4s\n",
      "29:\tlearn: 0.1829020\ttotal: 16.2s\tremaining: 10.8s\n",
      "30:\tlearn: 0.1817096\ttotal: 16.8s\tremaining: 10.3s\n",
      "31:\tlearn: 0.1807228\ttotal: 17.3s\tremaining: 9.72s\n",
      "32:\tlearn: 0.1795238\ttotal: 17.8s\tremaining: 9.17s\n",
      "33:\tlearn: 0.1784063\ttotal: 18.3s\tremaining: 8.62s\n",
      "34:\tlearn: 0.1775291\ttotal: 18.8s\tremaining: 8.08s\n",
      "35:\tlearn: 0.1763584\ttotal: 19.4s\tremaining: 7.54s\n",
      "36:\tlearn: 0.1754784\ttotal: 19.9s\tremaining: 7s\n",
      "37:\tlearn: 0.1747499\ttotal: 20.4s\tremaining: 6.46s\n",
      "38:\tlearn: 0.1740678\ttotal: 21s\tremaining: 5.92s\n",
      "39:\tlearn: 0.1733642\ttotal: 21.5s\tremaining: 5.38s\n",
      "40:\tlearn: 0.1727244\ttotal: 22s\tremaining: 4.83s\n",
      "41:\tlearn: 0.1717083\ttotal: 22.6s\tremaining: 4.29s\n",
      "42:\tlearn: 0.1709179\ttotal: 23.1s\tremaining: 3.76s\n",
      "43:\tlearn: 0.1702196\ttotal: 23.6s\tremaining: 3.22s\n",
      "44:\tlearn: 0.1694470\ttotal: 24.1s\tremaining: 2.68s\n",
      "45:\tlearn: 0.1686900\ttotal: 24.7s\tremaining: 2.15s\n",
      "46:\tlearn: 0.1678152\ttotal: 25.2s\tremaining: 1.61s\n",
      "47:\tlearn: 0.1672629\ttotal: 25.7s\tremaining: 1.07s\n",
      "48:\tlearn: 0.1666713\ttotal: 26.3s\tremaining: 536ms\n",
      "49:\tlearn: 0.1656884\ttotal: 26.8s\tremaining: 0us\n",
      "[CV] END ..................................learning_rate=0.2; total time=  33.6s\n",
      "0:\tlearn: 0.5068847\ttotal: 551ms\tremaining: 27s\n",
      "1:\tlearn: 0.3996237\ttotal: 1.08s\tremaining: 26s\n",
      "2:\tlearn: 0.3319275\ttotal: 1.62s\tremaining: 25.4s\n",
      "3:\tlearn: 0.2929602\ttotal: 2.16s\tremaining: 24.9s\n",
      "4:\tlearn: 0.2679667\ttotal: 2.7s\tremaining: 24.3s\n",
      "5:\tlearn: 0.2507390\ttotal: 3.23s\tremaining: 23.7s\n",
      "6:\tlearn: 0.2399153\ttotal: 3.78s\tremaining: 23.2s\n",
      "7:\tlearn: 0.2322608\ttotal: 4.31s\tremaining: 22.6s\n",
      "8:\tlearn: 0.2262315\ttotal: 4.84s\tremaining: 22s\n",
      "9:\tlearn: 0.2219450\ttotal: 5.37s\tremaining: 21.5s\n",
      "10:\tlearn: 0.2183570\ttotal: 5.92s\tremaining: 21s\n",
      "11:\tlearn: 0.2149542\ttotal: 6.45s\tremaining: 20.4s\n",
      "12:\tlearn: 0.2121180\ttotal: 6.99s\tremaining: 19.9s\n",
      "13:\tlearn: 0.2089233\ttotal: 7.53s\tremaining: 19.4s\n",
      "14:\tlearn: 0.2065640\ttotal: 8.05s\tremaining: 18.8s\n",
      "15:\tlearn: 0.2043817\ttotal: 8.62s\tremaining: 18.3s\n",
      "16:\tlearn: 0.2020487\ttotal: 9.17s\tremaining: 17.8s\n",
      "17:\tlearn: 0.2003255\ttotal: 9.73s\tremaining: 17.3s\n",
      "18:\tlearn: 0.1985908\ttotal: 10.3s\tremaining: 16.8s\n",
      "19:\tlearn: 0.1972683\ttotal: 10.8s\tremaining: 16.3s\n",
      "20:\tlearn: 0.1958916\ttotal: 11.4s\tremaining: 15.7s\n",
      "21:\tlearn: 0.1943653\ttotal: 12s\tremaining: 15.2s\n",
      "22:\tlearn: 0.1931163\ttotal: 12.5s\tremaining: 14.7s\n",
      "23:\tlearn: 0.1918267\ttotal: 13s\tremaining: 14.1s\n",
      "24:\tlearn: 0.1897963\ttotal: 13.6s\tremaining: 13.6s\n",
      "25:\tlearn: 0.1884569\ttotal: 14.2s\tremaining: 13.1s\n",
      "26:\tlearn: 0.1871292\ttotal: 14.7s\tremaining: 12.5s\n",
      "27:\tlearn: 0.1861942\ttotal: 15.3s\tremaining: 12s\n",
      "28:\tlearn: 0.1849256\ttotal: 15.8s\tremaining: 11.5s\n",
      "29:\tlearn: 0.1835310\ttotal: 16.3s\tremaining: 10.9s\n",
      "30:\tlearn: 0.1824079\ttotal: 16.9s\tremaining: 10.4s\n",
      "31:\tlearn: 0.1816154\ttotal: 17.4s\tremaining: 9.81s\n",
      "32:\tlearn: 0.1807793\ttotal: 18s\tremaining: 9.26s\n",
      "33:\tlearn: 0.1799521\ttotal: 18.5s\tremaining: 8.7s\n",
      "34:\tlearn: 0.1786428\ttotal: 19s\tremaining: 8.15s\n",
      "35:\tlearn: 0.1777582\ttotal: 19.6s\tremaining: 7.6s\n",
      "36:\tlearn: 0.1769713\ttotal: 20.1s\tremaining: 7.06s\n",
      "37:\tlearn: 0.1762010\ttotal: 20.6s\tremaining: 6.51s\n",
      "38:\tlearn: 0.1749189\ttotal: 21.2s\tremaining: 5.97s\n",
      "39:\tlearn: 0.1742301\ttotal: 21.7s\tremaining: 5.42s\n",
      "40:\tlearn: 0.1734904\ttotal: 22.2s\tremaining: 4.88s\n",
      "41:\tlearn: 0.1727456\ttotal: 22.7s\tremaining: 4.33s\n",
      "42:\tlearn: 0.1721355\ttotal: 23.3s\tremaining: 3.79s\n",
      "43:\tlearn: 0.1711866\ttotal: 23.8s\tremaining: 3.25s\n",
      "44:\tlearn: 0.1705685\ttotal: 24.3s\tremaining: 2.7s\n",
      "45:\tlearn: 0.1695913\ttotal: 24.9s\tremaining: 2.16s\n",
      "46:\tlearn: 0.1687800\ttotal: 25.4s\tremaining: 1.62s\n",
      "47:\tlearn: 0.1682347\ttotal: 25.9s\tremaining: 1.08s\n",
      "48:\tlearn: 0.1676691\ttotal: 26.5s\tremaining: 540ms\n",
      "49:\tlearn: 0.1671078\ttotal: 27s\tremaining: 0us\n",
      "[CV] END ..................................learning_rate=0.2; total time=  33.5s\n",
      "0:\tlearn: 0.5106516\ttotal: 550ms\tremaining: 26.9s\n",
      "1:\tlearn: 0.3977266\ttotal: 1.13s\tremaining: 27.1s\n",
      "2:\tlearn: 0.3297202\ttotal: 1.68s\tremaining: 26.3s\n",
      "3:\tlearn: 0.2897864\ttotal: 2.24s\tremaining: 25.7s\n",
      "4:\tlearn: 0.2669839\ttotal: 2.77s\tremaining: 24.9s\n",
      "5:\tlearn: 0.2497961\ttotal: 3.32s\tremaining: 24.3s\n",
      "6:\tlearn: 0.2374801\ttotal: 3.87s\tremaining: 23.7s\n",
      "7:\tlearn: 0.2295397\ttotal: 4.4s\tremaining: 23.1s\n",
      "8:\tlearn: 0.2241772\ttotal: 4.94s\tremaining: 22.5s\n",
      "9:\tlearn: 0.2197879\ttotal: 5.47s\tremaining: 21.9s\n",
      "10:\tlearn: 0.2162053\ttotal: 6s\tremaining: 21.3s\n",
      "11:\tlearn: 0.2128602\ttotal: 6.53s\tremaining: 20.7s\n",
      "12:\tlearn: 0.2102518\ttotal: 7.06s\tremaining: 20.1s\n",
      "13:\tlearn: 0.2071035\ttotal: 7.6s\tremaining: 19.5s\n",
      "14:\tlearn: 0.2048798\ttotal: 8.13s\tremaining: 19s\n",
      "15:\tlearn: 0.2025994\ttotal: 8.67s\tremaining: 18.4s\n",
      "16:\tlearn: 0.1997543\ttotal: 9.21s\tremaining: 17.9s\n",
      "17:\tlearn: 0.1969874\ttotal: 9.75s\tremaining: 17.3s\n",
      "18:\tlearn: 0.1955281\ttotal: 10.3s\tremaining: 16.8s\n",
      "19:\tlearn: 0.1941940\ttotal: 10.8s\tremaining: 16.2s\n",
      "20:\tlearn: 0.1927486\ttotal: 11.3s\tremaining: 15.7s\n",
      "21:\tlearn: 0.1908882\ttotal: 11.9s\tremaining: 15.1s\n",
      "22:\tlearn: 0.1897303\ttotal: 12.4s\tremaining: 14.6s\n",
      "23:\tlearn: 0.1885130\ttotal: 12.9s\tremaining: 14s\n",
      "24:\tlearn: 0.1872388\ttotal: 13.5s\tremaining: 13.5s\n",
      "25:\tlearn: 0.1857240\ttotal: 14s\tremaining: 12.9s\n",
      "26:\tlearn: 0.1847820\ttotal: 14.5s\tremaining: 12.4s\n",
      "27:\tlearn: 0.1837860\ttotal: 15.1s\tremaining: 11.8s\n",
      "28:\tlearn: 0.1825471\ttotal: 15.6s\tremaining: 11.3s\n",
      "29:\tlearn: 0.1813549\ttotal: 16.1s\tremaining: 10.8s\n",
      "30:\tlearn: 0.1804484\ttotal: 16.7s\tremaining: 10.2s\n",
      "31:\tlearn: 0.1794526\ttotal: 17.2s\tremaining: 9.67s\n",
      "32:\tlearn: 0.1786441\ttotal: 17.7s\tremaining: 9.13s\n",
      "33:\tlearn: 0.1774285\ttotal: 18.3s\tremaining: 8.59s\n",
      "34:\tlearn: 0.1766064\ttotal: 18.8s\tremaining: 8.05s\n",
      "35:\tlearn: 0.1756366\ttotal: 19.3s\tremaining: 7.51s\n",
      "36:\tlearn: 0.1749171\ttotal: 19.8s\tremaining: 6.97s\n",
      "37:\tlearn: 0.1741285\ttotal: 20.4s\tremaining: 6.43s\n",
      "38:\tlearn: 0.1733007\ttotal: 20.9s\tremaining: 5.89s\n",
      "39:\tlearn: 0.1726005\ttotal: 21.4s\tremaining: 5.36s\n",
      "40:\tlearn: 0.1715085\ttotal: 22s\tremaining: 4.82s\n",
      "41:\tlearn: 0.1709284\ttotal: 22.5s\tremaining: 4.28s\n",
      "42:\tlearn: 0.1703501\ttotal: 23s\tremaining: 3.75s\n",
      "43:\tlearn: 0.1697244\ttotal: 23.5s\tremaining: 3.21s\n",
      "44:\tlearn: 0.1690809\ttotal: 24.1s\tremaining: 2.67s\n",
      "45:\tlearn: 0.1683689\ttotal: 24.6s\tremaining: 2.14s\n",
      "46:\tlearn: 0.1676803\ttotal: 25.1s\tremaining: 1.6s\n",
      "47:\tlearn: 0.1671212\ttotal: 25.6s\tremaining: 1.07s\n",
      "48:\tlearn: 0.1661656\ttotal: 26.2s\tremaining: 534ms\n",
      "49:\tlearn: 0.1651146\ttotal: 26.7s\tremaining: 0us\n",
      "[CV] END ..................................learning_rate=0.2; total time=  33.2s\n",
      "0:\tlearn: 0.5057380\ttotal: 813ms\tremaining: 39.8s\n",
      "1:\tlearn: 0.3950410\ttotal: 1.55s\tremaining: 37.2s\n",
      "2:\tlearn: 0.3282338\ttotal: 2.28s\tremaining: 35.7s\n",
      "3:\tlearn: 0.2899052\ttotal: 3.01s\tremaining: 34.6s\n",
      "4:\tlearn: 0.2654133\ttotal: 3.75s\tremaining: 33.7s\n",
      "5:\tlearn: 0.2504207\ttotal: 4.49s\tremaining: 32.9s\n",
      "6:\tlearn: 0.2375019\ttotal: 5.24s\tremaining: 32.2s\n",
      "7:\tlearn: 0.2299742\ttotal: 5.98s\tremaining: 31.4s\n",
      "8:\tlearn: 0.2243708\ttotal: 6.75s\tremaining: 30.7s\n",
      "9:\tlearn: 0.2200230\ttotal: 7.47s\tremaining: 29.9s\n",
      "10:\tlearn: 0.2163129\ttotal: 8.24s\tremaining: 29.2s\n",
      "11:\tlearn: 0.2134177\ttotal: 8.96s\tremaining: 28.4s\n",
      "12:\tlearn: 0.2099507\ttotal: 9.69s\tremaining: 27.6s\n",
      "13:\tlearn: 0.2074863\ttotal: 10.4s\tremaining: 26.8s\n",
      "14:\tlearn: 0.2047933\ttotal: 11.2s\tremaining: 26s\n",
      "15:\tlearn: 0.2029474\ttotal: 11.9s\tremaining: 25.2s\n",
      "16:\tlearn: 0.2007373\ttotal: 12.6s\tremaining: 24.5s\n",
      "17:\tlearn: 0.1988456\ttotal: 13.3s\tremaining: 23.7s\n",
      "18:\tlearn: 0.1973881\ttotal: 14s\tremaining: 22.9s\n",
      "19:\tlearn: 0.1956511\ttotal: 14.8s\tremaining: 22.1s\n",
      "20:\tlearn: 0.1939510\ttotal: 15.5s\tremaining: 21.4s\n",
      "21:\tlearn: 0.1926802\ttotal: 16.2s\tremaining: 20.6s\n",
      "22:\tlearn: 0.1913373\ttotal: 16.9s\tremaining: 19.9s\n",
      "23:\tlearn: 0.1902741\ttotal: 17.7s\tremaining: 19.1s\n",
      "24:\tlearn: 0.1886928\ttotal: 18.4s\tremaining: 18.4s\n",
      "25:\tlearn: 0.1868022\ttotal: 19.1s\tremaining: 17.6s\n",
      "26:\tlearn: 0.1858784\ttotal: 19.8s\tremaining: 16.9s\n",
      "27:\tlearn: 0.1845352\ttotal: 20.5s\tremaining: 16.1s\n",
      "28:\tlearn: 0.1836925\ttotal: 21.3s\tremaining: 15.4s\n",
      "29:\tlearn: 0.1828538\ttotal: 22s\tremaining: 14.6s\n",
      "30:\tlearn: 0.1819514\ttotal: 22.7s\tremaining: 13.9s\n",
      "31:\tlearn: 0.1807970\ttotal: 23.4s\tremaining: 13.2s\n",
      "32:\tlearn: 0.1796927\ttotal: 24.1s\tremaining: 12.4s\n",
      "33:\tlearn: 0.1785277\ttotal: 24.8s\tremaining: 11.7s\n",
      "34:\tlearn: 0.1777588\ttotal: 25.5s\tremaining: 10.9s\n",
      "35:\tlearn: 0.1770882\ttotal: 26.2s\tremaining: 10.2s\n",
      "36:\tlearn: 0.1763206\ttotal: 26.9s\tremaining: 9.46s\n",
      "37:\tlearn: 0.1755903\ttotal: 27.6s\tremaining: 8.73s\n",
      "38:\tlearn: 0.1746327\ttotal: 28.4s\tremaining: 8s\n",
      "39:\tlearn: 0.1738360\ttotal: 29.1s\tremaining: 7.28s\n",
      "40:\tlearn: 0.1730021\ttotal: 29.8s\tremaining: 6.55s\n",
      "41:\tlearn: 0.1723174\ttotal: 30.6s\tremaining: 5.82s\n",
      "42:\tlearn: 0.1714247\ttotal: 31.3s\tremaining: 5.09s\n",
      "43:\tlearn: 0.1707604\ttotal: 32s\tremaining: 4.37s\n",
      "44:\tlearn: 0.1701439\ttotal: 32.7s\tremaining: 3.63s\n",
      "45:\tlearn: 0.1695390\ttotal: 33.4s\tremaining: 2.91s\n",
      "46:\tlearn: 0.1689578\ttotal: 34.1s\tremaining: 2.18s\n",
      "47:\tlearn: 0.1684679\ttotal: 34.8s\tremaining: 1.45s\n",
      "48:\tlearn: 0.1675538\ttotal: 35.6s\tremaining: 726ms\n",
      "49:\tlearn: 0.1670019\ttotal: 36.3s\tremaining: 0us\n",
      "Лучшие параметры: {'learning_rate': 0.2}\n",
      "F1-метрика на тренировочных данных: 0.6490579151878711\n",
      "Wall time: 6min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=stopwords_list, ngram_range=(1, 1))\n",
    "\n",
    "features_train_tfidf = tfidf_vectorizer.fit_transform(features_train['text'])\n",
    "features_test_tfidf = tfidf_vectorizer.transform(features_test['text'])\n",
    "\n",
    "\n",
    "catboost_classifier = CatBoostClassifier(class_weights=[1, 1], iterations=50)\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(catboost_classifier, param_grid, cv=3, scoring='f1', verbose=2)\n",
    "\n",
    "grid_search.fit(features_train_tfidf, target_train)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "best_cb_f1_train = grid_search.best_score_\n",
    "\n",
    "print(\"Лучшие параметры:\", best_params)\n",
    "print(\"F1-метрика на тренировочных данных:\", best_cb_f1_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "[CV] END classifier__learning_rate=0.01, tfidf__ngram_range=(1, 1); total time=   9.0s\n",
      "[CV] END classifier__learning_rate=0.01, tfidf__ngram_range=(1, 1); total time=   9.0s\n",
      "[CV] END classifier__learning_rate=0.01, tfidf__ngram_range=(1, 1); total time=   8.9s\n",
      "[CV] END classifier__learning_rate=0.01, tfidf__ngram_range=(1, 2); total time=  28.6s\n",
      "[CV] END classifier__learning_rate=0.01, tfidf__ngram_range=(1, 2); total time=  28.4s\n",
      "[CV] END classifier__learning_rate=0.01, tfidf__ngram_range=(1, 2); total time=  28.6s\n",
      "[CV] END classifier__learning_rate=0.1, tfidf__ngram_range=(1, 1); total time=   9.4s\n",
      "[CV] END classifier__learning_rate=0.1, tfidf__ngram_range=(1, 1); total time=   9.9s\n",
      "[CV] END classifier__learning_rate=0.1, tfidf__ngram_range=(1, 1); total time=   9.7s\n",
      "[CV] END classifier__learning_rate=0.1, tfidf__ngram_range=(1, 2); total time=  30.8s\n",
      "[CV] END classifier__learning_rate=0.1, tfidf__ngram_range=(1, 2); total time=  30.9s\n",
      "[CV] END classifier__learning_rate=0.1, tfidf__ngram_range=(1, 2); total time=  28.3s\n",
      "[CV] END classifier__learning_rate=0.2, tfidf__ngram_range=(1, 1); total time=   8.8s\n",
      "[CV] END classifier__learning_rate=0.2, tfidf__ngram_range=(1, 1); total time=   8.7s\n",
      "[CV] END classifier__learning_rate=0.2, tfidf__ngram_range=(1, 1); total time=   8.9s\n",
      "[CV] END classifier__learning_rate=0.2, tfidf__ngram_range=(1, 2); total time=  29.8s\n",
      "[CV] END classifier__learning_rate=0.2, tfidf__ngram_range=(1, 2); total time=  29.1s\n",
      "[CV] END classifier__learning_rate=0.2, tfidf__ngram_range=(1, 2); total time=  28.3s\n",
      "Лучшие параметры: {'classifier__learning_rate': 0.2, 'tfidf__ngram_range': (1, 1)}\n",
      "F1-метрика на тестовых данных: 0.6677268319279236\n",
      "Wall time: 5min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words=stopwords_list, ngram_range=(1, 1))), \n",
    "    ('classifier', LGBMClassifier(class_weight='balanced', n_estimators=5))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2)],  \n",
    "    'classifier__learning_rate': [0.01, 0.1, 0.2], \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring='f1', verbose=2)  \n",
    "\n",
    "grid_search.fit(features_train['text'], target_train)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "best_lgbm_f1_train = grid_search.best_score_\n",
    "\n",
    "print(\"Лучшие параметры:\", best_params)\n",
    "print(\"F1-метрика на тестовых данных:\", best_lgbm_f1_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на все результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-метрика на тренировочных  данных: 0.7790387356455555\n",
      "F1-метрика CatBoostClassifier на тренировочных данных: 0.6490579151878711\n",
      "F1-метрика LGBMClassifier на тренировочных данных: 0.6677268319279236\n"
     ]
    }
   ],
   "source": [
    "print(\"F1-метрика на тренировочных  данных:\", best_lr_f1_train)\n",
    "print(\"F1-метрика CatBoostClassifier на тренировочных данных:\", best_cb_f1_train)\n",
    "print(\"F1-метрика LGBMClassifier на тренировочных данных:\", best_lgbm_f1_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучший результат показывает модель `Logistic Regression`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат модели на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-метрика на тестовых данных: 0.7889630078835658\n"
     ]
    }
   ],
   "source": [
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "predicted_test = best_model.predict(features_test['text'])\n",
    "\n",
    "f1_test = f1_score(target_test, predicted_test)\n",
    "\n",
    "print(\"F1-метрика на тестовых данных:\", f1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рекомендую для предсказания точкисности комментариев использовать модель Логистической регрессии, по скольку она показывает лучший результат f1"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1426,
    "start_time": "2023-08-06T00:56:22.742Z"
   },
   {
    "duration": 2491,
    "start_time": "2023-08-06T00:56:45.340Z"
   },
   {
    "duration": 950,
    "start_time": "2023-08-06T00:57:07.223Z"
   },
   {
    "duration": 21,
    "start_time": "2023-08-06T00:57:08.174Z"
   },
   {
    "duration": 816,
    "start_time": "2023-08-06T01:00:11.394Z"
   },
   {
    "duration": 7,
    "start_time": "2023-08-06T01:00:13.103Z"
   },
   {
    "duration": 4,
    "start_time": "2023-08-06T01:00:23.601Z"
   },
   {
    "duration": 882,
    "start_time": "2023-08-06T01:00:23.771Z"
   },
   {
    "duration": 7,
    "start_time": "2023-08-06T01:00:24.655Z"
   },
   {
    "duration": 874,
    "start_time": "2023-08-06T01:00:46.764Z"
   },
   {
    "duration": 6,
    "start_time": "2023-08-06T01:00:48.268Z"
   },
   {
    "duration": 206,
    "start_time": "2023-08-06T01:04:22.444Z"
   },
   {
    "duration": 3,
    "start_time": "2023-08-06T01:12:08.985Z"
   },
   {
    "duration": 7260,
    "start_time": "2023-08-06T01:17:42.147Z"
   },
   {
    "duration": 8,
    "start_time": "2023-08-06T01:18:12.870Z"
   },
   {
    "duration": 8,
    "start_time": "2023-08-06T01:21:36.623Z"
   },
   {
    "duration": 131,
    "start_time": "2023-08-06T01:21:52.570Z"
   },
   {
    "duration": 350,
    "start_time": "2023-08-06T01:22:15.800Z"
   },
   {
    "duration": 26,
    "start_time": "2023-08-06T01:22:18.875Z"
   },
   {
    "duration": 10,
    "start_time": "2023-08-06T01:22:27.517Z"
   },
   {
    "duration": 610,
    "start_time": "2023-08-06T01:22:33.363Z"
   },
   {
    "duration": 6,
    "start_time": "2023-08-06T01:22:40.591Z"
   },
   {
    "duration": 8,
    "start_time": "2023-08-06T01:22:47.045Z"
   },
   {
    "duration": 6,
    "start_time": "2023-08-06T01:22:51.557Z"
   },
   {
    "duration": 13,
    "start_time": "2023-08-06T01:23:02.967Z"
   },
   {
    "duration": 66,
    "start_time": "2023-08-06T01:24:11.471Z"
   },
   {
    "duration": 218,
    "start_time": "2023-08-06T01:24:15.143Z"
   },
   {
    "duration": 70,
    "start_time": "2023-08-06T01:24:30.651Z"
   },
   {
    "duration": 83,
    "start_time": "2023-08-06T01:24:43.442Z"
   },
   {
    "duration": 79,
    "start_time": "2023-08-06T01:24:49.535Z"
   },
   {
    "duration": 74,
    "start_time": "2023-08-06T01:25:39.572Z"
   },
   {
    "duration": 6,
    "start_time": "2023-08-06T01:27:39.881Z"
   },
   {
    "duration": 7,
    "start_time": "2023-08-06T01:32:34.564Z"
   },
   {
    "duration": 71,
    "start_time": "2023-08-06T02:03:18.944Z"
   },
   {
    "duration": 76,
    "start_time": "2023-08-06T02:05:46.245Z"
   },
   {
    "duration": 8,
    "start_time": "2023-08-06T02:05:47.903Z"
   },
   {
    "duration": 88,
    "start_time": "2023-08-06T02:05:48.271Z"
   },
   {
    "duration": 32,
    "start_time": "2023-08-06T02:05:53.637Z"
   },
   {
    "duration": 10,
    "start_time": "2023-08-06T02:14:31.826Z"
   },
   {
    "duration": 36,
    "start_time": "2023-08-06T02:14:32.282Z"
   },
   {
    "duration": 33,
    "start_time": "2023-08-06T02:14:52.073Z"
   },
   {
    "duration": 55,
    "start_time": "2023-08-06T02:27:36.591Z"
   },
   {
    "duration": 39,
    "start_time": "2023-08-06T02:27:47.348Z"
   },
   {
    "duration": 227,
    "start_time": "2023-08-06T02:28:08.233Z"
   },
   {
    "duration": 6,
    "start_time": "2023-08-06T02:28:27.607Z"
   },
   {
    "duration": 11817,
    "start_time": "2023-08-06T02:28:44.335Z"
   },
   {
    "duration": 11,
    "start_time": "2023-08-06T02:38:29.920Z"
   },
   {
    "duration": 19,
    "start_time": "2023-08-06T02:38:45.391Z"
   },
   {
    "duration": 11,
    "start_time": "2023-08-06T02:38:50.219Z"
   },
   {
    "duration": 1787,
    "start_time": "2023-08-06T02:39:07.272Z"
   },
   {
    "duration": 930,
    "start_time": "2023-08-06T02:39:09.060Z"
   },
   {
    "duration": 15,
    "start_time": "2023-08-06T02:39:09.992Z"
   },
   {
    "duration": 267,
    "start_time": "2023-08-06T02:39:10.010Z"
   },
   {
    "duration": 8248,
    "start_time": "2023-08-06T02:39:10.280Z"
   },
   {
    "duration": 8,
    "start_time": "2023-08-06T02:39:18.530Z"
   },
   {
    "duration": 36,
    "start_time": "2023-08-06T02:39:18.540Z"
   },
   {
    "duration": 53,
    "start_time": "2023-08-06T02:39:18.577Z"
   },
   {
    "duration": 5,
    "start_time": "2023-08-06T02:39:18.632Z"
   },
   {
    "duration": 113,
    "start_time": "2023-08-06T02:39:18.639Z"
   },
   {
    "duration": 10,
    "start_time": "2023-08-06T02:39:18.754Z"
   },
   {
    "duration": 12779,
    "start_time": "2023-08-06T02:39:18.766Z"
   },
   {
    "duration": 91,
    "start_time": "2023-08-06T02:45:37.026Z"
   },
   {
    "duration": 132,
    "start_time": "2023-08-06T02:50:09.435Z"
   },
   {
    "duration": 6,
    "start_time": "2023-08-06T02:50:46.271Z"
   },
   {
    "duration": 17,
    "start_time": "2023-08-06T02:50:50.095Z"
   },
   {
    "duration": 1752,
    "start_time": "2023-08-06T03:15:43.102Z"
   },
   {
    "duration": 928,
    "start_time": "2023-08-06T03:15:44.856Z"
   },
   {
    "duration": 13,
    "start_time": "2023-08-06T03:15:45.789Z"
   },
   {
    "duration": 251,
    "start_time": "2023-08-06T03:15:45.804Z"
   },
   {
    "duration": 7345,
    "start_time": "2023-08-06T03:15:46.057Z"
   },
   {
    "duration": 8,
    "start_time": "2023-08-06T03:15:53.404Z"
   },
   {
    "duration": 42,
    "start_time": "2023-08-06T03:15:53.414Z"
   },
   {
    "duration": 44,
    "start_time": "2023-08-06T03:15:53.458Z"
   },
   {
    "duration": 8,
    "start_time": "2023-08-06T03:15:53.504Z"
   },
   {
    "duration": 108,
    "start_time": "2023-08-06T03:15:53.514Z"
   },
   {
    "duration": 11,
    "start_time": "2023-08-06T03:15:53.624Z"
   },
   {
    "duration": 11391,
    "start_time": "2023-08-06T03:15:53.636Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-06T03:20:32.143Z"
   },
   {
    "duration": 2388,
    "start_time": "2023-08-06T21:13:44.642Z"
   },
   {
    "duration": 2807,
    "start_time": "2023-08-06T21:13:48.124Z"
   },
   {
    "duration": 3549,
    "start_time": "2023-08-06T21:13:50.934Z"
   },
   {
    "duration": 12,
    "start_time": "2023-08-06T21:13:55.685Z"
   },
   {
    "duration": 242,
    "start_time": "2023-08-06T21:13:57.258Z"
   },
   {
    "duration": 7306,
    "start_time": "2023-08-06T21:13:59.269Z"
   },
   {
    "duration": 4,
    "start_time": "2023-08-06T21:14:15.621Z"
   },
   {
    "duration": 9,
    "start_time": "2023-08-06T21:14:17.602Z"
   },
   {
    "duration": 1948,
    "start_time": "2023-08-06T21:15:08.758Z"
   },
   {
    "duration": 920,
    "start_time": "2023-08-06T21:15:11.979Z"
   },
   {
    "duration": 12,
    "start_time": "2023-08-06T21:15:13.765Z"
   },
   {
    "duration": 259,
    "start_time": "2023-08-06T21:15:15.138Z"
   },
   {
    "duration": 6789,
    "start_time": "2023-08-06T21:15:16.768Z"
   },
   {
    "duration": 8,
    "start_time": "2023-08-06T21:15:28.025Z"
   },
   {
    "duration": 5606,
    "start_time": "2023-08-06T21:15:47.545Z"
   },
   {
    "duration": 13,
    "start_time": "2023-08-06T21:15:53.155Z"
   },
   {
    "duration": 1941,
    "start_time": "2023-08-06T21:16:09.146Z"
   },
   {
    "duration": 950,
    "start_time": "2023-08-06T21:16:11.090Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-06T21:16:12.042Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-06T21:16:12.043Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-06T21:16:12.044Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-06T21:16:12.045Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-06T21:16:12.046Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-06T21:16:12.047Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-06T21:16:12.049Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-06T21:16:12.050Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-06T21:16:12.052Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-06T21:16:12.053Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-06T21:16:12.054Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-06T21:16:12.054Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-06T21:16:12.056Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-06T21:16:12.057Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-06T21:16:12.058Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-06T21:16:12.059Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-06T21:16:12.060Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-06T21:16:12.061Z"
   },
   {
    "duration": 798,
    "start_time": "2023-08-06T21:16:15.363Z"
   },
   {
    "duration": 2153,
    "start_time": "2023-08-06T21:16:22.205Z"
   },
   {
    "duration": 27,
    "start_time": "2023-08-06T21:16:24.361Z"
   },
   {
    "duration": 2103,
    "start_time": "2023-08-06T21:16:47.002Z"
   },
   {
    "duration": 1943,
    "start_time": "2023-08-06T21:16:49.108Z"
   },
   {
    "duration": 890,
    "start_time": "2023-08-06T21:16:53.601Z"
   },
   {
    "duration": 10,
    "start_time": "2023-08-06T21:16:54.493Z"
   },
   {
    "duration": 251,
    "start_time": "2023-08-06T21:16:54.674Z"
   },
   {
    "duration": 6798,
    "start_time": "2023-08-06T21:16:56.711Z"
   },
   {
    "duration": 4761,
    "start_time": "2023-08-06T21:17:09.498Z"
   },
   {
    "duration": 10,
    "start_time": "2023-08-06T21:17:22.684Z"
   },
   {
    "duration": 4,
    "start_time": "2023-08-06T21:17:48.849Z"
   },
   {
    "duration": 141,
    "start_time": "2023-08-06T21:17:49.075Z"
   },
   {
    "duration": 4,
    "start_time": "2023-08-06T21:18:11.003Z"
   },
   {
    "duration": 11,
    "start_time": "2023-08-06T21:18:11.180Z"
   },
   {
    "duration": 13,
    "start_time": "2023-08-06T21:18:42.717Z"
   },
   {
    "duration": 315,
    "start_time": "2023-08-06T21:19:11.701Z"
   },
   {
    "duration": 318,
    "start_time": "2023-08-06T21:19:30.793Z"
   },
   {
    "duration": 2206,
    "start_time": "2023-08-06T21:20:46.428Z"
   },
   {
    "duration": 2069,
    "start_time": "2023-08-06T21:20:48.637Z"
   },
   {
    "duration": 968,
    "start_time": "2023-08-06T21:20:51.915Z"
   },
   {
    "duration": 13,
    "start_time": "2023-08-06T21:20:53.683Z"
   },
   {
    "duration": 259,
    "start_time": "2023-08-06T21:20:56.317Z"
   },
   {
    "duration": 1173,
    "start_time": "2023-08-06T21:20:58.079Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-06T21:20:59.254Z"
   },
   {
    "duration": 2204,
    "start_time": "2023-08-06T21:21:18.249Z"
   },
   {
    "duration": 2242,
    "start_time": "2023-08-06T21:21:20.455Z"
   },
   {
    "duration": 983,
    "start_time": "2023-08-06T21:21:23.288Z"
   },
   {
    "duration": 16,
    "start_time": "2023-08-06T21:21:24.274Z"
   },
   {
    "duration": 269,
    "start_time": "2023-08-06T21:21:25.630Z"
   },
   {
    "duration": 1199,
    "start_time": "2023-08-06T21:21:26.482Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-06T21:21:27.683Z"
   },
   {
    "duration": 7,
    "start_time": "2023-08-06T21:21:27.747Z"
   },
   {
    "duration": 334,
    "start_time": "2023-08-06T21:21:49.207Z"
   },
   {
    "duration": 324,
    "start_time": "2023-08-06T21:22:11.833Z"
   },
   {
    "duration": 4527,
    "start_time": "2023-08-06T21:22:26.647Z"
   },
   {
    "duration": 11,
    "start_time": "2023-08-06T21:22:38.053Z"
   },
   {
    "duration": 13,
    "start_time": "2023-08-06T21:22:45.684Z"
   },
   {
    "duration": 3700,
    "start_time": "2023-08-06T21:22:52.453Z"
   },
   {
    "duration": 8,
    "start_time": "2023-08-06T21:22:56.825Z"
   },
   {
    "duration": 1113,
    "start_time": "2023-08-06T21:23:03.222Z"
   },
   {
    "duration": 333,
    "start_time": "2023-08-06T21:23:18.404Z"
   },
   {
    "duration": 3357,
    "start_time": "2023-08-06T21:24:49.961Z"
   },
   {
    "duration": 7,
    "start_time": "2023-08-06T21:24:53.320Z"
   },
   {
    "duration": 345,
    "start_time": "2023-08-06T21:24:53.329Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-06T21:24:53.676Z"
   },
   {
    "duration": 339,
    "start_time": "2023-08-06T21:25:19.526Z"
   },
   {
    "duration": 3358,
    "start_time": "2023-08-06T21:25:23.978Z"
   },
   {
    "duration": 7,
    "start_time": "2023-08-06T21:25:27.338Z"
   },
   {
    "duration": 398,
    "start_time": "2023-08-06T21:25:27.347Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-06T21:25:27.747Z"
   },
   {
    "duration": 2182,
    "start_time": "2023-08-06T21:26:00.288Z"
   },
   {
    "duration": 2006,
    "start_time": "2023-08-06T21:26:02.473Z"
   },
   {
    "duration": 890,
    "start_time": "2023-08-06T21:26:04.481Z"
   },
   {
    "duration": 14,
    "start_time": "2023-08-06T21:26:05.374Z"
   },
   {
    "duration": 261,
    "start_time": "2023-08-06T21:26:05.390Z"
   },
   {
    "duration": 4193,
    "start_time": "2023-08-06T21:26:05.653Z"
   },
   {
    "duration": 8,
    "start_time": "2023-08-06T21:26:09.848Z"
   },
   {
    "duration": 584,
    "start_time": "2023-08-06T21:26:09.867Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-06T21:26:10.453Z"
   },
   {
    "duration": 10,
    "start_time": "2023-08-06T21:26:44.070Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-06T21:28:19.016Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-06T21:28:19.018Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-06T21:28:19.018Z"
   },
   {
    "duration": 1989,
    "start_time": "2023-08-06T21:29:04.092Z"
   },
   {
    "duration": 1910,
    "start_time": "2023-08-06T21:29:06.084Z"
   },
   {
    "duration": 861,
    "start_time": "2023-08-06T21:29:07.995Z"
   },
   {
    "duration": 15,
    "start_time": "2023-08-06T21:29:08.858Z"
   },
   {
    "duration": 252,
    "start_time": "2023-08-06T21:29:08.875Z"
   },
   {
    "duration": 4034,
    "start_time": "2023-08-06T21:29:09.129Z"
   },
   {
    "duration": 8,
    "start_time": "2023-08-06T21:29:13.166Z"
   },
   {
    "duration": 5,
    "start_time": "2023-08-06T21:29:14.507Z"
   },
   {
    "duration": 9086,
    "start_time": "2023-08-06T21:29:21.493Z"
   },
   {
    "duration": 2041,
    "start_time": "2023-08-06T21:31:15.652Z"
   },
   {
    "duration": 1994,
    "start_time": "2023-08-06T21:31:17.696Z"
   },
   {
    "duration": 869,
    "start_time": "2023-08-06T21:31:19.691Z"
   },
   {
    "duration": 13,
    "start_time": "2023-08-06T21:31:20.562Z"
   },
   {
    "duration": 264,
    "start_time": "2023-08-06T21:31:20.577Z"
   },
   {
    "duration": 4355,
    "start_time": "2023-08-06T21:31:20.843Z"
   },
   {
    "duration": 7,
    "start_time": "2023-08-06T21:31:25.200Z"
   },
   {
    "duration": 9,
    "start_time": "2023-08-06T21:31:25.209Z"
   },
   {
    "duration": 1267753,
    "start_time": "2023-08-06T21:31:25.219Z"
   },
   {
    "duration": 10,
    "start_time": "2023-08-06T21:52:32.976Z"
   },
   {
    "duration": 14,
    "start_time": "2023-08-06T21:52:32.989Z"
   },
   {
    "duration": 15,
    "start_time": "2023-08-06T21:52:33.005Z"
   },
   {
    "duration": 124,
    "start_time": "2023-08-06T21:52:33.021Z"
   },
   {
    "duration": 5,
    "start_time": "2023-08-06T21:52:33.147Z"
   },
   {
    "duration": 1714,
    "start_time": "2023-08-06T21:52:33.168Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-06T21:52:34.884Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-06T21:52:34.885Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-06T21:52:34.886Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-06T21:52:34.887Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-06T21:52:34.889Z"
   },
   {
    "duration": 0,
    "start_time": "2023-08-06T21:52:34.890Z"
   },
   {
    "duration": 62,
    "start_time": "2023-08-06T21:53:51.369Z"
   },
   {
    "duration": 14,
    "start_time": "2023-08-06T21:57:19.142Z"
   },
   {
    "duration": 66,
    "start_time": "2023-08-06T22:47:05.491Z"
   },
   {
    "duration": 88,
    "start_time": "2023-08-06T23:07:40.862Z"
   },
   {
    "duration": 184,
    "start_time": "2023-08-06T23:07:58.432Z"
   },
   {
    "duration": 82,
    "start_time": "2023-08-06T23:08:05.323Z"
   },
   {
    "duration": 43,
    "start_time": "2023-08-06T23:10:47.269Z"
   },
   {
    "duration": 37,
    "start_time": "2023-08-06T23:11:15.592Z"
   },
   {
    "duration": 137,
    "start_time": "2023-08-06T23:11:36.573Z"
   },
   {
    "duration": 13,
    "start_time": "2023-08-06T23:12:19.481Z"
   },
   {
    "duration": 142,
    "start_time": "2023-08-06T23:12:22.439Z"
   },
   {
    "duration": 1163,
    "start_time": "2023-08-06T23:18:43.930Z"
   },
   {
    "duration": 1027,
    "start_time": "2023-08-06T23:18:58.477Z"
   },
   {
    "duration": 1089,
    "start_time": "2023-08-06T23:19:13.530Z"
   },
   {
    "duration": 1189,
    "start_time": "2023-08-06T23:20:41.359Z"
   },
   {
    "duration": 88,
    "start_time": "2023-08-06T23:21:59.945Z"
   },
   {
    "duration": 70,
    "start_time": "2023-08-06T23:22:03.350Z"
   },
   {
    "duration": 77,
    "start_time": "2023-08-06T23:22:37.110Z"
   },
   {
    "duration": 80,
    "start_time": "2023-08-06T23:22:39.927Z"
   },
   {
    "duration": 73,
    "start_time": "2023-08-06T23:23:01.437Z"
   },
   {
    "duration": 1991,
    "start_time": "2023-08-06T23:24:02.810Z"
   },
   {
    "duration": 1892,
    "start_time": "2023-08-06T23:24:04.803Z"
   },
   {
    "duration": 839,
    "start_time": "2023-08-06T23:24:06.697Z"
   },
   {
    "duration": 10,
    "start_time": "2023-08-06T23:24:07.538Z"
   },
   {
    "duration": 255,
    "start_time": "2023-08-06T23:24:07.550Z"
   },
   {
    "duration": 3915,
    "start_time": "2023-08-06T23:24:07.806Z"
   },
   {
    "duration": 7,
    "start_time": "2023-08-06T23:24:11.723Z"
   },
   {
    "duration": 8,
    "start_time": "2023-08-06T23:24:15.252Z"
   },
   {
    "duration": 4,
    "start_time": "2023-08-06T23:24:18.043Z"
   },
   {
    "duration": 11,
    "start_time": "2023-08-06T23:24:18.286Z"
   },
   {
    "duration": 91,
    "start_time": "2023-08-06T23:24:20.073Z"
   },
   {
    "duration": 5,
    "start_time": "2023-08-06T23:24:22.753Z"
   },
   {
    "duration": 198,
    "start_time": "2023-08-06T23:24:23.994Z"
   },
   {
    "duration": 1209,
    "start_time": "2023-08-06T23:25:00.130Z"
   },
   {
    "duration": 5,
    "start_time": "2023-08-06T23:26:29.570Z"
   },
   {
    "duration": 7,
    "start_time": "2023-08-06T23:26:42.766Z"
   },
   {
    "duration": 5,
    "start_time": "2023-08-06T23:27:02.062Z"
   },
   {
    "duration": 11,
    "start_time": "2023-08-06T23:28:01.392Z"
   },
   {
    "duration": 2002,
    "start_time": "2023-08-06T23:28:45.694Z"
   },
   {
    "duration": 1919,
    "start_time": "2023-08-06T23:28:47.699Z"
   },
   {
    "duration": 848,
    "start_time": "2023-08-06T23:28:49.619Z"
   },
   {
    "duration": 12,
    "start_time": "2023-08-06T23:28:50.470Z"
   },
   {
    "duration": 260,
    "start_time": "2023-08-06T23:28:50.484Z"
   },
   {
    "duration": 4035,
    "start_time": "2023-08-06T23:28:50.746Z"
   },
   {
    "duration": 7,
    "start_time": "2023-08-06T23:28:54.784Z"
   },
   {
    "duration": 7,
    "start_time": "2023-08-06T23:28:54.793Z"
   },
   {
    "duration": 4,
    "start_time": "2023-08-06T23:28:54.802Z"
   },
   {
    "duration": 10,
    "start_time": "2023-08-06T23:28:54.809Z"
   },
   {
    "duration": 54,
    "start_time": "2023-08-06T23:28:54.821Z"
   },
   {
    "duration": 102,
    "start_time": "2023-08-06T23:28:54.877Z"
   },
   {
    "duration": 12,
    "start_time": "2023-08-06T23:28:56.593Z"
   },
   {
    "duration": 5,
    "start_time": "2023-08-06T23:28:59.240Z"
   },
   {
    "duration": 6953,
    "start_time": "2023-08-06T23:29:01.126Z"
   },
   {
    "duration": 350478,
    "start_time": "2023-08-06T23:30:09.847Z"
   },
   {
    "duration": 2910,
    "start_time": "2023-08-07T19:19:04.515Z"
   },
   {
    "duration": 3442,
    "start_time": "2023-08-07T19:19:07.428Z"
   },
   {
    "duration": 3572,
    "start_time": "2023-08-07T19:19:10.872Z"
   },
   {
    "duration": 12,
    "start_time": "2023-08-07T19:19:14.446Z"
   },
   {
    "duration": 249,
    "start_time": "2023-08-07T19:19:14.460Z"
   },
   {
    "duration": 4238,
    "start_time": "2023-08-07T19:19:14.711Z"
   },
   {
    "duration": 10,
    "start_time": "2023-08-07T19:19:18.951Z"
   },
   {
    "duration": 12,
    "start_time": "2023-08-07T19:19:18.963Z"
   },
   {
    "duration": 1583512,
    "start_time": "2023-08-07T19:19:18.977Z"
   },
   {
    "duration": 8,
    "start_time": "2023-08-07T19:45:42.493Z"
   },
   {
    "duration": 61,
    "start_time": "2023-08-07T19:45:42.503Z"
   },
   {
    "duration": 141,
    "start_time": "2023-08-07T19:45:42.566Z"
   },
   {
    "duration": 12,
    "start_time": "2023-08-07T19:45:42.709Z"
   },
   {
    "duration": 52,
    "start_time": "2023-08-07T19:45:42.723Z"
   },
   {
    "duration": 1515918,
    "start_time": "2023-08-07T19:45:42.777Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
